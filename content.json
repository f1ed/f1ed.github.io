{"pages":[],"posts":[{"title":"「机器学习-李宏毅」：Gradient","text":"总结「李宏毅老师-机器学习」的Gradient，主要从以下三个方面展开：调节learning rate；加快训练速度；对数据进行Feature Scaling。 Tip 1: Tuning your learning rates carefullyVisualize 损失函数随着参数变化的函数图 左图是Loss Function的函数图，红色是最好的Step，当Step过小（蓝色），会花费很多时间，当Step过大（绿色、黄色），会发现Loss越来越大，找不到最低点。 所以在Training中，尽可能的visualize loss值的变化。 但是当参数大于等于三个时， $loss function$的函数图就不能visualize了。 因此，在右图中，visualize Loss随着参数更新的变化，横轴即迭代次数，当图像呈现蓝色（small）时，就可以把learning rate 调大一些。 Adaptive Learning Rates(Adagrad)但是手动调节 $\\eta$是低效的，我们更希望能自动地调节。 直观上的原则是： $\\eta$ 的大小应该随着迭代次数的增加而变小。 最开始，初始点离minima很远，那step应该大一些，所以learning rate也应该大一些。 随着迭代次数的增加，离minima越来越近，就应该减小 learning rate。 E.g. 1/t decay： $\\eta^t=\\eta/ \\sqrt{t+1}$ 不同参数的 $\\eta$应该不同（cannot be one-size-fits-all)。 AdagradAdagrad 的主要思想是：Divide the learning rate of each parameter by the root mean squear of its previous derivatives.(通过除这个参数的 计算出的所有导数 的均方根) root mean squar : $ \\sqrt{\\frac{1}{n}(x_1^2+x_2^2+...+x_n^2)} $ Vanilla Gradient descent $w^{t+1} \\leftarrow w^{t}-\\eta^{t} g^{t}$ Adagrad $w^{t+1} \\leftarrow w^{t}-\\frac{\\eta^{t}}{\\sigma^{t}} g^{t} $ $\\eta^t$：第t次迭代的leaning rate $ \\eta^{t}=\\frac{\\eta}{\\sqrt{t+1}}$ $g^{t}=\\frac{\\partial L\\left(\\theta^{t}\\right)}{\\partial w} $ $\\sigma^t$：root mean squar of previous derivatives of w $\\tau^{t}=\\sqrt{\\frac{1}{t+1} \\sum_{i=0}^{t}\\left(g^{i}\\right)^{2}} $ 对比上面两种Adaptive Gradient，Adagrade的优势是learning rate 是和parameter dependent（参数相关的）。 Adagrad步骤简化步骤： 简化公式： $ w^{t+1} \\leftarrow w^{t}-\\frac{\\eta}{\\sqrt{\\sum_{i=0}^{t}\\left(g^{i}\\right)^{2}}} g^{t}$ ( $ \\eta^{t}=\\frac{\\eta}{\\sqrt{t+1}} $ , $ \\sigma^{t}=\\sqrt{\\frac{1}{t+1} \\sum_{i=0}^{t}\\left(g^{i}\\right)^{2}}$ ,约掉共同项即可) Adagrad Contradiction? ——Adagrad原理解释Vanilla Gradient descent $w^{t+1} \\leftarrow w^{t}-\\eta^{t} g^{t}$ Adagrad $ w^{t+1} \\leftarrow w^{t}-\\frac{\\eta}{\\sqrt{\\sum_{i=0}^{t}\\left(g^{i}\\right)^{2}}} g^{t}$ 在Vanilla Gradient descent中， $g^t$越大，也就是当前梯度大，也就有更大的step。 而在Adagrad中，当 $g^t$越大，有更大的step,而当 $\\sqrt{\\sum_{i=0}^t (g^i)^2} $ 越大，反而有更小step。 Contradiction？ Intuitive Reason（直观上解释） $ w^{t+1} \\leftarrow w^{t}-\\frac{\\eta}{\\sqrt{\\sum_{i=0}^{t}\\left(g^{i}\\right)^{2}}} g^{t}$ $\\sqrt{\\sum_{i=0}^t (g^i)^2} $ 是为了造成反差的效果。 类比一下，如果一个一直很凶的人，突然温柔了一些，你会觉得他特别温柔。所以同样是 $0.1$,第一行中，你会觉得特别大，第二行中，你会觉得特别小。 因此 $\\sqrt{\\sum_{i=0}^t (g^i)^2} $ 这一项的存在就能体现 $g^t$的变化有多surprise。 数学一些的解释Larger Gradient,larger steps?在前面我们都深信不疑这一点，但这样的描述真的是正确的吗？ 在这张图中，只有一个参数，认为当该点的导数越大，离minima越远，这样看来，Larger Gradient,larger steps是正确的。 在上图中的 $x_0$点，该点迭代更新的best step 应该正比于 $|x_0+\\frac{b}{2a}|$ ，即 $\\frac{|2,a, x_0+b|}{2a}$。 而 $\\frac{|2,a, x_0+b|}{2a}$的分子也就是该点的一阶导数的绝对值。 上图中，有 $w_1,w_2$两个参数。 横着用蓝色的线切一刀，得到的是 $w_2$ 固定，loss随着 $w_1$变化的图像：比较a、b两点，a点导数大，离minima远。 竖着用绿色的线切一刀，得到的是 $w_2$ 固定，loss随着 $w_1$变化的图像：比较c、d两点，c点导数大，离minima远。 但是，如果比较a、c两点呢？ a点对 $w_1$ 的偏导数和c点对 $w_2$的偏导数比较？ 比较出来，c点点偏导数更大，离minima更远吗？ 再看左图的图像，横着的弧度更平滑，竖着的弧度更尖一些，直观上看应该c点离minima更近一些。 所以Larger Gradient,larger steps点比较方法不能（cross parameters)跨参数比较。 所以最好的step $\\propto$ 一阶导数（Do not cross parameters)。 Second Derivative 前面讨论best step $\\frac{|2,a, x_0+b|}{2a}$的分子是该点一阶导数，那么其分母呢？ 当对一阶导数再求导时，可以发现其二阶导数就是best step的分母。 得出结论：the best step $\\propto$ |First dertivative| / Second derivative。 因此，再来看两个参数的情况，比较a点和c点，a点的一阶导数更小，二阶导数也更小；c点点一阶导数更大，二阶导数也更大。 所以如果要比较a、c两点，谁离minima更远，应该比较其一阶导数的绝对值除以其二阶导数的大小。 回到 $ w^{t+1} \\leftarrow w^{t}-\\frac{\\eta}{\\sqrt{\\sum_{i=0}^{t}\\left(g^{i}\\right)^{2}}} g^{t}$ 上一部分得出的结论是：the best step $\\propto$ |First dertivative| / Second derivative。 所以我们的learning rate 也应该和 |First dertivative| / Second derivative相关。 $g^t$也就是一阶导数，但为什么 $\\sqrt{\\sum_{i=0}^t (g^i)^2} $ 能代表二阶导数呢？ 上图中，蓝色的函数图有更小的二阶导数，绿色的函数图有更大的二阶导数。 在复杂函数中，求二阶导数是一个很复杂的计算。 所以我们想用一阶导数来反映二阶导数的大小。 在一阶导数的函数图中，认为一阶导数值更小的，二阶导数也更小，但是取一个点显然是片面的，所以考虑取多个点。 也就是用 $ \\sqrt{\\text{(first derivative)}^2}$ 来代表best step中的二阶导数。 总结一下Adagrad的为了找寻最好的learning rate，从找寻best step下手，用简单的二次函数为例，得出 best step $\\propto$ |First dertivative| / Second derivative。 但是复杂函数的二阶导数是难计算的，因此考虑用多个点的一阶导数来反映其二阶导数。 得出 $ w^{t+1} \\leftarrow w^{t}-\\frac{\\eta}{\\sqrt{\\sum_{i=0}^{t}\\left(g^{i}\\right)^{2}}} g^{t}$ 。 直观来解释公式中的一阶导数的root mean square，即来为该次迭代的一阶导数造成反差效果。 其他文献中的Adaptive Gradient理应都是为了调节learning rate使之有best step。(待补充的其他Gradient)[1] Tip 2:Stochastic Gradient DescentStochastic Gradient Descent在linear model中，我们这样计算Loss function： $L=\\sum_{n}\\left(\\hat{y}^{n}-\\left(b+\\sum w_{i} x_{i}^{n}\\right)\\right)^{2} $ 每求一次Loss function，L都对所有training examples的 $\\text{error}^2$求和，因此每一次的loss function的计算，都是一重循环。 在Stochastic Gradient Descent中，每一次求loss function，只取一个example $x^n$，减少一重循环，无疑更快。 Stochastic Gradient Descent Pick an example $x^n$ $L=\\left(\\hat{y}^{n}-\\left(b+\\sum w_{i} x_{i}^{n}\\right)\\right)^{2} $ 上图中，传统的Gradient Descent看完一次所有的examples，离minima还很远；而Stochastic Gradient Descent ，看完一次，已经离minima较近了。 Tip 3:Feature ScalingWhat is Feature Scaling 如上图所示，希望能让不同的feature能有相同的scale（定义域/规模） Why Feature Scaling假设model都是 $y = b+ w_1 x_1 +w_2 x_2$。 上图中，左边 $x_2$的规模更大，可以认为 $x_1$ 对loss 的影响更小， $ x_2$对loss的影响更大。 即当 $w_1,w_2$轻微扰动时，同时加上相同的 $\\Delta w$时，$x_2$ 使 $y$的取值更大，那么对loss 的影响也更大。 如图中下方的函数图 $w_1$方向的L更平滑， $w_2$ 方向更陡峭些，Gradient descent的步骤如图所示。 但当对 $x_2$进行feature scaling后，图像会更像正圆，Gradient descent使，参数更新向着圆心走，更新会更有效率。 How Feature Scaling概率论知识：标准化。 概率论： 随机变量 $X$ 的期望和方差均存在，且 $ D(X)&gt;0$,令 $X^*=\\frac{X-E(X)}{\\sqrt{D(X)}} $ ，那么 $E(X^)=0,D(X)=1$, $X^$称为X的标准化随机变量。 对所有向量的每一维度，进行标准化处理： $x_{i}^{r} \\leftarrow \\frac{x_{i}^{r}-m_{i}}{\\sigma_{i}} $ { % endraw %} （ $m_i$是该维度变量的均值， $\\sigma_i$ 是该维度变量的方差） 标准化后，每一个feature的期望都是0，方差都是1。 # Gradient Descent Theory（公式推导） 当用Gradient Descent解决 $\\theta^*=\\arg \\min_\\theta L(\\theta)$时，我们希望每次更新 $\\theta $ 都能得到 $L(\\theta^0)>L(\\theta^1)>L(\\theta^2)>...$ 这样的理论结果，但是不总能得到这样的结果。 [![3gb0Wd.md.png](https://s2.ax1x.com/2020/03/01/3gb0Wd.md.png)](https://imgchr.com/i/3gb0Wd) 上图中，我们虽然不能一下知道minima的方向，但是我们希望：当给一个点 $\\theta^0$ 时，我们能很容易的知道他附近（极小的附近）的最小的loss 是哪个方向。 所以怎么做呢？ ## Tylor Series 微积分知识：Taylor Series（泰勒公式）。 > Tylor Series: > > 函数 $h(x)$ 在 $x_0$ 无限可导，那么 {% raw %} $ \\begin{aligned} > \\mathrm{h}(\\mathrm{x}) &=\\sum_{k=0}^{\\infty} \\frac{\\mathrm{h}^{(k)}\\left(x_{0}\\right)}{k !}\\left(x-x_{0}\\right)^{k} \\\\ > &=h\\left(x_{0}\\right)+h^{\\prime}\\left(x_{0}\\right)\\left(x-x_{0}\\right)+\\frac{h^{\\prime \\prime}\\left(x_{0}\\right)}{2 !}\\left(x-x_{0}\\right)^{2}+\\ldots > \\end{aligned}$ {% endraw %} 当 x 无限接近 $x_0$ 时，忽略后面无穷小的高次项，{% raw %} **$h(x) \\approx h\\left(x_{0}\\right)+h^{\\prime}\\left(x_{0}\\right)\\left(x-x_{0}\\right) $** {% endraw %} 上图中，用 $\\pi/4$ 处的一阶泰勒展示来表达 $\\sin(x)$ ,图像是直线，和 $\\sin(x)$ 图像相差很大，但当 x无限接近 $\\pi/4$ 是，函数值估算很好。 Multivariable Taylor Series {% raw %} $h(x, y)=h\\left(x_{0}, y_{0}\\right)+\\frac{\\partial h\\left(x_{0}, y_{0}\\right)}{\\partial x}\\left(x-x_{0}\\right)+\\frac{\\partial h\\left(x_{0}, y_{0}\\right)}{\\partial y}\\left(y-y_{0}\\right) +\\text{something raleted to} (x-x_x^0)^2 \\text{and} (y-y_0)^2+…$ { % endraw %} 当 $(x,y)$ 接近 $(x_0,y_0)$ 时， $h(x,y)$ 用 $(x_0,y_0)$ 处的一阶泰勒展开式估计。 {% raw %} $ h(x, y) \\approx h\\left(x_{0}, y_{0}\\right)+\\frac{\\partial h\\left(x_{0}, y_{0}\\right)}{\\partial x}\\left(x-x_{0}\\right)+\\frac{\\partial h\\left(x_{0}, y_{0}\\right)}{\\partial y}\\left(y-y_{0}\\right)$ {% endraw %} Back to Formal Derivation 当图中的红色圆圈足够小时，红色圆圈中的loss 值就可以用 $(a,b)$ 处的一阶泰勒展开式来表示。 {% raw %} $\\mathrm{L}(\\theta) \\approx \\mathrm{L}(a, b)+\\frac{\\partial \\mathrm{L}(a, b)}{\\partial \\theta_{1}}\\left(\\theta_{1}-a\\right)+\\frac{\\partial \\mathrm{L}(a, b)}{\\partial \\theta_{2}}\\left(\\theta_{2}-b\\right) $ {% endraw %} $(\\theta_1-a)^2+(\\theta_2-b)^2 \\leq d^2$,d 足够小。 用 $s=L(a,b)$ , {% raw %} $u=\\frac{\\partial \\mathrm{L}(a, b)}{\\partial \\theta_{1}}, v=\\frac{\\partial \\mathrm{L}(a, b)}{\\partial \\theta_{2}} $ { % endraw %}表示。 **最后问题变成：** **{% raw %} $L(\\theta)\\approx s+u(\\theta_1-a)+v(\\theta_2-b)$ {% endraw %}** 找 $(\\theta_1,\\theta_2)$，且满足 $(\\theta_1-a)^2+(\\theta_2-b)^2 \\leq d^2$，使 $L(\\theta)$ 最小。 变成了一个简单的最优化问题。 令 $\\Delta \\theta_1=\\theta_1-a$ , $\\Delta\\theta_2=\\theta_2-b$ 问题简化为： $\\text{min}:u \\Delta \\theta_1+v\\Delta\\theta_2$ $\\text{subject to}:{\\Delta\\theta_1}^2+{\\Delta\\theta_2}^2\\leq d^2$ 画出图，就是初中数学了。更新的方向应该是 $(u,v)$ 向量反向的方向。 所以： {% raw %} $\\left[\\begin{array}{l} \\Delta \\theta_{1} \\\\ \\Delta \\theta_{2} \\end{array}\\right]=-\\eta\\left[\\begin{array}{l} u \\\\ v \\end{array}\\right] $ {% endraw %} {% raw %} $\\left[\\begin{array}{l} \\theta_{1} \\\\ \\theta_{2} \\end{array}\\right]=\\left[\\begin{array}{l} a \\\\ b \\end{array}\\right]-\\eta\\left[\\begin{array}{l} u \\\\ v \\end{array}\\right] $ {% endraw %} {% raw %} $\\left[\\begin{array}{l} \\theta_{1} \\\\ \\theta_{2} \\end{array}\\right]=\\left[\\begin{array}{l} a \\\\ b \\end{array}\\right]-\\eta\\left[\\begin{array}{l} u \\\\ v \\end{array}\\right]=\\left[\\begin{array}{l} a \\\\ b \\end{array}\\right]-\\eta\\left[\\begin{array}{l} \\frac{\\partial \\mathrm{L}(a, b)}{\\partial \\theta_{1}} \\\\ \\frac{\\partial \\mathrm{L}(a, b)}{\\partial \\theta_{2}} \\end{array}\\right] $ {% endraw %} Limitation of Gradient Descent Gradient Descent 可能会卡在local minima或者saddle point（鞍点：一个方向是极大值，一个方向是极小值，导数为0） 实践中，我们往往会在导数无穷接近0的时候停下来（&lt; 1e-7)，Gradient Descent 可能会停在plateau(高原；增长后的稳定) Reference[1] 待补充的其他Gradient","link":"/2020/03/01/Gradient/"},{"title":"「机器学习-李宏毅」：Regression","text":"在YouTube上看台大李宏毅老师的课，看完Regression讲座的感受就是： 好想去抓Pokemon！！！ 这篇文章将总结李宏毅老师Regression的讲座，并尝试实现其demo。 Regression（回归）DefineRegression：是找到一个$function$，进行预测。对输入的feature，输出一个$Scalar$(数值，标量)。 Example Application Look for a $function$ Stock Market Forecast（股票预测） $input$：过去的股价信息 $output$：明天的股价平均值（$Scalar$) Self-Driving Car(自动驾驶) $input$：路况信息 $output$：方向盘角度（$Scalar$) Recommendation（推荐系统） $input$：使用者A、商品B $output$：使用者A购买商品B的可能性 可见，$input$都是一些特征信息，$output$都是一个标量数值，这就是Regression。 Regression Case: Pokenmon 看完这节课，感想：好想去抓宝可梦QAQ 预测一个pokemon进化后的CP（Combat Power，战斗力）值。 为什么要预测呐？ 如果进化后的CP值高，就进化他，不然就把他当糖果，因为宝可梦很难抓的。（？没玩过，我也不懂o r z） 上图妙蛙种子的信息(可能的$input$)： $x_{cp}$：CP值 $x_s$:物种 $x_{hp}$:生命值 $x_w$:重量 $x_h$:高度 output：进化后的CP值。 $x_{cp}$：用下标表示一个object的component。 $x^1$：用上标表示一个完整的object。 Step 1: 找一个Model（function set）Model ：$y = b + w \\cdot x_{cp}$ 假设用上式作为我们的Model，那么这些函数： $ \\begin{aligned} &\\mathrm{f}_{1}: \\mathrm{y}=10.0+9.0 \\cdot \\mathrm{x}_{\\mathrm{cp}}\\\\ &f_{2}: y=9.8+9.2 \\cdot x_{c p}\\\\ &f_{3}: y=-0.8-1.2 \\cdot x_{c p} \\end{aligned} $ 等都属于这个集合，但是显然像$f_3$这种函数是bad，CP值不可能是负数。bad functions 很多，所以在下面的步骤，会说明如何判别一个函数的好坏，自动的选出最好的那个 $function$。 把Model 1一般化，得到线代中的 Linear Model：$y = b+\\sum w_ix_i$ $x_i$：x的feature $b$：bias,偏置值 $w_i$：weight，权重 Step 2: 判别Goodness of Function(Training Data)Training Data假定使用Model ：$y = b + w \\cdot x_{cp}$ Training Data：十只宝可梦，用向量的形式表示。 使用Training data来judge the goodness of function.。 Loss Function(损失函数)概率论：做线性回归，一般使用最小二乘法。一般回归，大多使用极大似然估计。 Loss function $L$ ：$L(f)=L(w,b)=\\sum_{n=1}^{10}(\\hat{y}^n-(b+w\\cdot x_{cp}^n))^2$ 其中的 $\\hat{y}^n-(b+w\\cdot x_{cp}^n)$是Estimation error(估测误差) Loss Function的意义：它的 $input$是一个 $function$，它的 $output$体现了how bad it is,这个函数有多糟/好。 Figure the Result 上图横纵坐标是函数 $L$的参数 $w 、b$，图中的每一个point都是一个 $function $。 color：体现函数的输出，越红越大，说明选择的函数越bad。 所以我们要选择紫色区域结果最小的函数。 而这个得到best function的过程是可以通过无数次迭代实现的。（重复的迭代当时是交给计算机做了） Step 3:迭代找出Best Function$L(w,b)=\\sum_{n=1}^{10}(\\hat{y}^n-(b+w\\cdot x_{cp}^n))^2$ 找到Best Function: $f^{*}=\\arg \\min _{f} L(f)$ 也就是找到参数 $w^{*},b^{*}=\\arg \\min_{w,b} L(w,b)=\\arg \\min_{w,b}\\sum_{n=1}^{10}(\\hat{y}^n-(b+w\\cdot x_{cp}^n))^2$ arg ：argument,变元 arg min：使之最小的变元 arg max：使之最大的变元 据悉，线性回归的参数可以用线性代数的知识，解出closed-form solution（解析解），我先挖个坑QAQ，以后来填这块知识。[1] 在机器学习中，只要$L$函数可微分， 即可用Gradient Descent（梯度下降）的方法来求解。 Gradient Decent（梯度下降）和概率论中的梯度下降估计参数的原理相同，只是计算机不能直接解出方程的解，所以计算机的方法是迭代。 考虑一个参数w*$w^*=\\arg \\min_w L(w)$ 步骤： 随机选取一个初始值 $w^0$ 计算 $ \\frac{{\\rm d}L}{{\\rm d}w}|_{w=w^0}$ &nbsp; &nbsp; $\\begin{equation} w^{1} \\leftarrow w^{0}-\\left.\\eta \\frac{d L}{d w}\\right|_{w=w^{0}} \\end{equation}$ 计算 $ \\frac{{\\rm d}L}{{\\rm d}w}|_{w=w^0}$ &nbsp;&nbsp; $\\begin{equation} w^{2} \\leftarrow w^{1}-\\left.\\eta \\frac{d L}{d w}\\right|_{w=w^{1}} \\end{equation}$ …until $ \\frac{{\\rm d}L}{{\\rm d}w}|_{w=w^n}=0$ 上图迭代过程的几点说明 $\\begin{equation}\\left.\\frac{\\mathrm{d} L}{\\mathrm{d} w}\\right|_{w=w^{i}}\\end{equation}$的正负 如果是negative，也就是该点切线斜率是负的，那应该Increse w，以找到最低点。 Negative $\\rightarrow$ Increase w Positive $\\rightarrow$ Decrease w $-\\left.\\eta \\frac{d L}{d w}\\right|_{w=w^{i}}$：步长 $\\eta$：learning rate（学习速度），事先设好的值。 $-$(负号)：如果 $\\begin{equation}\\left.\\frac{\\mathrm{d} L}{\\mathrm{d} w}\\right|_{w=w^{i}}\\end{equation}$是负的，应该增加w。 Local optimal：局部最优和全局最优 如果是以上图像，则得到的w不是全局最优。 但线性回归的损失函数是凸函数，存在一个全局最优，没有局部最优。 考虑多个参数 $w^{*},b^{*}$ 微积分知识：gradient（梯度，向量)： $\\nabla L=\\left[\\begin{array}{l}\\frac{\\partial L}{\\partial w} \\\\frac{\\partial L}{\\partial b}\\end{array}\\right]$ 考虑多个参数和考虑一个参数思路相同，每次迭代，迭代两个参数。 $w^{*}, b^{*}=\\arg \\min _{w, b} L(w, b)$ 步骤： 随机选取初值 $w^0,b^0$ 计算 $\\left.\\left.\\frac{\\partial L}{\\partial w}\\right|_{w=w^{0}, b=b^{0},} \\frac{\\partial L}{\\partial b}\\right|_{w=w^{0}, b=b^{0}}$ &nbsp; &nbsp; $w^{1} \\leftarrow w^{0}-\\left.\\eta \\frac{\\partial L}{\\partial w}\\right|_{w=w^{0}, b=b^{0}} \\quad b^{1} \\leftarrow b^{0}-\\left.\\eta \\frac{\\partial L}{\\partial b}\\right|_{w=w^{0}, b=b^{0}}$ 计算 $\\left.\\left.\\frac{\\partial L}{\\partial w}\\right|_{w=w^{1}, b=b^{1},} \\frac{\\partial L}{\\partial b}\\right|_{w=w^{1}, b=b^{1}}$ &nbsp; &nbsp; &nbsp; $w^{2} \\leftarrow w^{1}-\\left.\\eta \\frac{\\partial L}{\\partial w}\\right|_{w=w^{1}, b=b^{1}} \\quad b^{2} \\leftarrow b^{1}-\\left.\\eta \\frac{\\partial L}{\\partial b}\\right|_{w=w^{1}, b=b^{1}}$ …until $ \\frac{{\\rm d}L}{{\\rm d}w}|_{w=w^n}=0$, $ \\frac{{\\rm d}L}{{\\rm d}b}|_{b=b^n}=0$ 上图，坐标为 $L(w,b)$函数的参数，Color代表 $L$的大小，越紫值越小。 每一个点都是一个 $function$，沿着梯度方向（图中法线方向）迭代，找到全局最优点。 再次说明：线性回归中，损失函数是convex（凸函数），没有局部最优解。 $\\frac{\\partial L}{\\partial w}$和 $\\frac{\\partial L}{\\partial b}$的公式推导$L(w, b)=\\sum_{n=1}^{10}\\left(\\hat{y}^{n}-\\left(b+w \\cdot x_{c p}^{n}\\right)\\right)^{2}$ 微积分的知识，显然。 数学真香。———我自己 $\\frac{\\partial L}{\\partial w}=\\sum_{n=1}^{10}2\\left(\\hat{y}^{n}-\\left(b+w \\cdot x_{c p}^{n}\\right)\\right)（-x_{cp}^n)$ $\\frac{\\partial L}{\\partial b}=\\sum_{n=1}^{10}2\\left(\\hat{y}^{n}-\\left(b+w \\cdot x_{c p}^{n}\\right)\\right)(-1)$ 实际结果分析Training Data Training Data的Error=31.9，但我们真正关心的是Testing Data的error。 Testing Data 是new Data：另外的Pokemon！。 Testing DataModel 1： $y = b+w\\cdot x_{cp}$ error = 35,比Training Data error更大。 Model 2：$y = b+w_1\\cdot x_{cp}+w_2\\cdot (x_{cp})^2$ Testing error=18.4，比Model 1 好。 Model 3：$y = b+w_1\\cdot x_{cp}+w_2\\cdot (x_{cp})^2+w_3\\cdot(x_{cp})^3$ Testing error=18.1，比Model 2好。 Model 4:$y = b+w_1\\cdot x_{cp}+w_2\\cdot (x_{cp})^2+w_3\\cdot(x_{cp})^3+w_4 \\cdot (x_{cp})^4$ Testing error =28.8,比Model3更差。 Model 5：$y = b+w_1\\cdot x_{cp}+w_2\\cdot (x_{cp})^2+w_3\\cdot(x_{cp})^3+w_4 \\cdot (x_{cp})^4+w_5\\cdot (x_{cp})^5$ Testing error = 232.1,爆炸了一样的差。 Overfiting（过拟合了）从上面5个Model中可以得出，越复杂的函数模型，在Testing data上不一定能得到更好的结果。（过拟合使Training data 的误差越来越小） 所以在选择Model时，需要选择合适的Model。 对模型进行改进如果收集更多的Training Data，可以发现他好像不是一个Linear Model。 Back to step 1:Redesigh the Model从上面那张图，感觉他不是一个Linear Model,而是需要if 是伊布，模型是…，if 是…,可见是和物种有关系。 （很抱歉，我只认识右上角时伊布，QAQ，我也说不出名字） 但用 $\\delta$(微积分学的狄拉克函数)表示条件语句，可以发现，他仍然是一个线性模型。 $\\delta(x_s= \\text{Pidgey)}\\left\\{\\begin{array}{ll}=1 & \\text { If } x_{s}=\\text { Pidgey } \\\\ =0 & \\text { otherwise }\\end{array}\\right.$ $y = b_1\\cdot \\delta_1+w_1\\cdot \\delta_1+b2\\cdot \\delta_2+w_2\\cdot \\delta_2+…$是一个linear model。 拟合出来，Training Data 和Testing Data的error都蛮小的。 如果想让拟合误差更小，还可以考虑其他的feature，重量、高度、HP等。 但同样的，如果函数过于复杂，也会出现Overfitting的情况。 Back to Step 2:Regularization（正则化）对于Linear Model :$y = b+\\sum w_i x_i$ 为什么要正则化？我们希望得到的函数是较平滑的，这样测试时，函数的输出对输入的noise不sensitive，即输入x的细微扰动，并不太会影响输出的结果。 所以当参数越接近0，函数越平滑。因此在原本的loss function后加入 $\\lambda \\sum(w_i)^2$项（ $\\lambda$需手调），可以保证函数较平滑。 正则化： $L = \\sum_n(\\hat{y}^n-(b+\\sum w_i x_i))^2 + \\lambda\\sum(w_i)^2$ $\\lambda $大小的选择 可以得出结论： $\\lambda $越大，Training Error变大了。 当 $\\lambda$更大，损失函数更考虑w参数的取值，更关心函数的平滑程度，而更少的关心拟合的error。 $\\lambda $越大，Testing Error变小了，当 $\\lambda$过大时，又变大。 $\\lambda $较小时，$\\lambda $增大，函数更平滑，能良好适应数据的扰动。 $\\lambda $较大时，函数过于平滑，宛如直线，这显然不能准确预测。 因此，在调节$\\lambda $大小时，也要适当选择。 正则化的一个注意点在regularization中，我们只考虑了w参数，没有考虑bias偏置值参数。 因为正则化是寻找较平滑拟合，而偏置参数只是让函数平移，与平滑无关。 Again：Regularization不考虑bias Fllowing Gradient descent[2] Overfitting and regularization[3] Validation[4] 由于博主也是在学习阶段，学习后，会po上下面内容的链接。 希望能在学习、写博客的过程中，锻炼自己的表达能力，尽量让文风言简意赅又科学严谨。 写博客是为了记录与分享，感谢指正。 Reference[1] “周志华西瓜书p55,待补充” [2] [3] [4]","link":"/2020/02/27/Regression/"}],"tags":[{"name":"机器学习","slug":"机器学习","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"Gradient","slug":"Gradient","link":"/tags/Gradient/"},{"name":"公开课","slug":"公开课","link":"/tags/%E5%85%AC%E5%BC%80%E8%AF%BE/"},{"name":"Regression","slug":"Regression","link":"/tags/Regression/"}],"categories":[{"name":"机器学习-李宏毅","slug":"机器学习-李宏毅","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%9D%8E%E5%AE%8F%E6%AF%85/"}]}