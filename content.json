{"pages":[],"posts":[{"title":"「机器学习-李宏毅」：Regression","text":"在YouTube上看台大李宏毅老师的课，看完Regression讲座的感受就是： 好想去抓Pokemon！！！ 这篇文章将总结李宏毅老师Regression的讲座，并尝试实现其demo。 Regression（回归）DefineRegression：是找到一个$function$，进行预测。对输入的feature，输出一个$Scalar$(数值，标量)。 Example Application Look for a $function$ Stock Market Forecast（股票预测） $input$：过去的股价信息 $output$：明天的股价平均值（$Scalar$) Self-Driving Car(自动驾驶) $input$：路况信息 $output$：方向盘角度（$Scalar$) Recommendation（推荐系统） $input$：使用者A、商品B $output$：使用者A购买商品B的可能性 可见，$input$都是一些特征信息，$output$都是一个标量数值，这就是Regression。 Regression Case: Pokenmon 看完这节课，感想：好想去抓宝可梦QAQ 预测一个pokemon进化后的CP（Combat Power，战斗力）值。 为什么要预测呐？ 如果进化后的CP值高，就进化他，不然就把他当糖果，因为宝可梦很难抓的。（？没玩过，我也不懂o r z） 上图妙蛙种子的信息(可能的$input$)： $x_{cp}$：CP值 $x_s$:物种 $x_{hp}$:生命值 $x_w$:重量 $x_h$:高度 output：进化后的CP值。 $x_{cp}$：用下标表示一个object的component。 $x^1$：用上标表示一个完整的object。 Step 1: 找一个Model（function set）Model ：$y = b + w \\cdot x_{cp}$ 假设用上式作为我们的Model，那么这些函数： $ \\begin{aligned} &\\mathrm{f}_{1}: \\mathrm{y}=10.0+9.0 \\cdot \\mathrm{x}_{\\mathrm{cp}}\\\\ &f_{2}: y=9.8+9.2 \\cdot x_{c p}\\\\ &f_{3}: y=-0.8-1.2 \\cdot x_{c p} \\end{aligned} $ 等都属于这个集合，但是显然像$f_3$这种函数是bad，CP值不可能是负数。bad functions 很多，所以在下面的步骤，会说明如何判别一个函数的好坏，自动的选出最好的那个 $function$。 把Model 1一般化，得到线代中的 Linear Model：$y = b+\\sum w_ix_i$ $x_i$：x的feature $b$：bias,偏置值 $w_i$：weight，权重 Step 2: 判别Goodness of Function(Training Data)Training Data假定使用Model ：$y = b + w \\cdot x_{cp}$ Training Data：十只宝可梦，用向量的形式表示。 使用Training data来judge the goodness of function.。 Loss Function(损失函数)概率论：做线性回归，一般使用最小二乘法。一般回归，大多使用极大似然估计。 Loss function $L$ ：$L(f)=L(w,b)=\\sum_{n=1}^{10}(\\hat{y}^n-(b+w\\cdot x_{cp}^n))^2$ 其中的 $\\hat{y}^n-(b+w\\cdot x_{cp}^n)$是Estimation error(估测误差) Loss Function的意义：它的 $input$是一个 $function$，它的 $output$体现了how bad it is,这个函数有多糟/好。 Figure the Result 上图横纵坐标是函数 $L$的参数 $w 、b$，图中的每一个point都是一个 $function $。 color：体现函数的输出，越红越大，说明选择的函数越bad。 所以我们要选择紫色区域结果最小的函数。 而这个得到best function的过程是可以通过无数次迭代实现的。（重复的迭代当时是交给计算机做了） Step 3:迭代找出Best Function$L(w,b)=\\sum_{n=1}^{10}(\\hat{y}^n-(b+w\\cdot x_{cp}^n))^2$ 找到Best Function: $f^{*}=\\arg \\min _{f} L(f)$ 也就是找到参数 $w^{*},b^{*}=\\arg \\min_{w,b} L(w,b)=\\arg \\min_{w,b}\\sum_{n=1}^{10}(\\hat{y}^n-(b+w\\cdot x_{cp}^n))^2$ arg ：argument,变元 arg min：使之最小的变元 arg max：使之最大的变元 据悉，线性回归的参数可以用线性代数的知识，解出closed-form solution（解析解），我先挖个坑QAQ，以后来填这块知识。[1] 在机器学习中，只要$L$函数可微分， 即可用Gradient Descent（梯度下降）的方法来求解。 Gradient Decent（梯度下降）和概率论中的梯度下降估计参数的原理相同，只是计算机不能直接解出方程的解，所以计算机的方法是迭代。 考虑一个参数w*$w^*=\\arg \\min_w L(w)$ 步骤： 随机选取一个初始值 $w^0$ 计算 $ \\frac{{\\rm d}L}{{\\rm d}w}|_{w=w^0}$ &nbsp; &nbsp; $\\begin{equation} w^{1} \\leftarrow w^{0}-\\left.\\eta \\frac{d L}{d w}\\right|_{w=w^{0}} \\end{equation}$ 计算 $ \\frac{{\\rm d}L}{{\\rm d}w}|_{w=w^0}$ &nbsp;&nbsp; $\\begin{equation} w^{2} \\leftarrow w^{1}-\\left.\\eta \\frac{d L}{d w}\\right|_{w=w^{1}} \\end{equation}$ …until $ \\frac{{\\rm d}L}{{\\rm d}w}|_{w=w^n}=0$ 上图迭代过程的几点说明 $\\begin{equation}\\left.\\frac{\\mathrm{d} L}{\\mathrm{d} w}\\right|_{w=w^{i}}\\end{equation}$的正负 如果是negative，也就是该点切线斜率是负的，那应该Increse w，以找到最低点。 Negative $\\rightarrow$ Increase w Positive $\\rightarrow$ Decrease w $-\\left.\\eta \\frac{d L}{d w}\\right|_{w=w^{i}}$：步长 $\\eta$：learning rate（学习速度），事先设好的值。 $-$(负号)：如果 $\\begin{equation}\\left.\\frac{\\mathrm{d} L}{\\mathrm{d} w}\\right|_{w=w^{i}}\\end{equation}$是负的，应该增加w。 Local optimal：局部最优和全局最优 如果是以上图像，则得到的w不是全局最优。 但线性回归的损失函数是凸函数，存在一个全局最优，没有局部最优。 考虑多个参数 $w^{*},b^{*}$ 微积分知识：gradient（梯度，向量)： $\\nabla L=\\left[\\begin{array}{l}\\frac{\\partial L}{\\partial w} \\\\frac{\\partial L}{\\partial b}\\end{array}\\right]$ 考虑多个参数和考虑一个参数思路相同，每次迭代，迭代两个参数。 $w^{*}, b^{*}=\\arg \\min _{w, b} L(w, b)$ 步骤： 随机选取初值 $w^0,b^0$ 计算 $\\left.\\left.\\frac{\\partial L}{\\partial w}\\right|_{w=w^{0}, b=b^{0},} \\frac{\\partial L}{\\partial b}\\right|_{w=w^{0}, b=b^{0}}$ &nbsp; &nbsp; $w^{1} \\leftarrow w^{0}-\\left.\\eta \\frac{\\partial L}{\\partial w}\\right|_{w=w^{0}, b=b^{0}} \\quad b^{1} \\leftarrow b^{0}-\\left.\\eta \\frac{\\partial L}{\\partial b}\\right|_{w=w^{0}, b=b^{0}}$ 计算 $\\left.\\left.\\frac{\\partial L}{\\partial w}\\right|_{w=w^{1}, b=b^{1},} \\frac{\\partial L}{\\partial b}\\right|_{w=w^{1}, b=b^{1}}$ &nbsp; &nbsp; &nbsp; $w^{2} \\leftarrow w^{1}-\\left.\\eta \\frac{\\partial L}{\\partial w}\\right|_{w=w^{1}, b=b^{1}} \\quad b^{2} \\leftarrow b^{1}-\\left.\\eta \\frac{\\partial L}{\\partial b}\\right|_{w=w^{1}, b=b^{1}}$ …until $ \\frac{{\\rm d}L}{{\\rm d}w}|_{w=w^n}=0$, $ \\frac{{\\rm d}L}{{\\rm d}b}|_{b=b^n}=0$ 上图，坐标为 $L(w,b)$函数的参数，Color代表 $L$的大小，越紫值越小。 每一个点都是一个 $function$，沿着梯度方向（图中法线方向）迭代，找到全局最优点。 再次说明：线性回归中，损失函数是convex（凸函数），没有局部最优解。 $\\frac{\\partial L}{\\partial w}$和 $\\frac{\\partial L}{\\partial b}$的公式推导$L(w, b)=\\sum_{n=1}^{10}\\left(\\hat{y}^{n}-\\left(b+w \\cdot x_{c p}^{n}\\right)\\right)^{2}$ 微积分的知识，显然。 数学真香。———我自己 $\\frac{\\partial L}{\\partial w}=\\sum_{n=1}^{10}2\\left(\\hat{y}^{n}-\\left(b+w \\cdot x_{c p}^{n}\\right)\\right)（-x_{cp}^n)$ $\\frac{\\partial L}{\\partial b}=\\sum_{n=1}^{10}2\\left(\\hat{y}^{n}-\\left(b+w \\cdot x_{c p}^{n}\\right)\\right)(-1)$ 实际结果分析Training Data Training Data的Error=31.9，但我们真正关心的是Testing Data的error。 Testing Data 是new Data：另外的Pokemon！。 Testing DataModel 1： $y = b+w\\cdot x_{cp}$ error = 35,比Training Data error更大。 Model 2：$y = b+w_1\\cdot x_{cp}+w_2\\cdot (x_{cp})^2$ Testing error=18.4，比Model 1 好。 Model 3：$y = b+w_1\\cdot x_{cp}+w_2\\cdot (x_{cp})^2+w_3\\cdot(x_{cp})^3$ Testing error=18.1，比Model 2好。 Model 4:$y = b+w_1\\cdot x_{cp}+w_2\\cdot (x_{cp})^2+w_3\\cdot(x_{cp})^3+w_4 \\cdot (x_{cp})^4$ Testing error =28.8,比Model3更差。 Model 5：$y = b+w_1\\cdot x_{cp}+w_2\\cdot (x_{cp})^2+w_3\\cdot(x_{cp})^3+w_4 \\cdot (x_{cp})^4+w_5\\cdot (x_{cp})^5$ Testing error = 232.1,爆炸了一样的差。 Overfiting（过拟合了）从上面5个Model中可以得出，越复杂的函数模型，在Testing data上不一定能得到更好的结果。（过拟合使Training data 的误差越来越小） 所以在选择Model时，需要选择合适的Model。 对模型进行改进如果收集更多的Training Data，可以发现他好像不是一个Linear Model。 Back to step 1:Redesigh the Model从上面那张图，感觉他不是一个Linear Model,而是需要if 是伊布，模型是…，if 是…,可见是和物种有关系。 （很抱歉，我只认识右上角时伊布，QAQ，我也说不出名字） 但用 $\\delta$(微积分学的狄拉克函数)表示条件语句，可以发现，他仍然是一个线性模型。 $\\delta(x_s= \\text{Pidgey)}\\left\\{\\begin{array}{ll}=1 & \\text { If } x_{s}=\\text { Pidgey } \\\\ =0 & \\text { otherwise }\\end{array}\\right.$ $y = b_1\\cdot \\delta_1+w_1\\cdot \\delta_1+b2\\cdot \\delta_2+w_2\\cdot \\delta_2+…$是一个linear model。 拟合出来，Training Data 和Testing Data的error都蛮小的。 如果想让拟合误差更小，还可以考虑其他的feature，重量、高度、HP等。 但同样的，如果函数过于复杂，也会出现Overfitting的情况。 Back to Step 2:Regularization（正则化）对于Linear Model :$y = b+\\sum w_i x_i$ 为什么要正则化？我们希望得到的函数是较平滑的，这样测试时，函数的输出对输入的noise不sensitive，即输入x的细微扰动，并不太会影响输出的结果。 所以当参数越接近0，函数越平滑。因此在原本的loss function后加入 $\\lambda \\sum(w_i)^2$项（ $\\lambda$需手调），可以保证函数较平滑。 正则化： $L = \\sum_n(\\hat{y}^n-(b+\\sum w_i x_i))^2 + \\lambda\\sum(w_i)^2$ $\\lambda $大小的选择 可以得出结论： $\\lambda $越大，Training Error变大了。 当 $\\lambda$更大，损失函数更考虑w参数的取值，更关心函数的平滑程度，而更少的关心拟合的error。 $\\lambda $越大，Testing Error变小了，当 $\\lambda$过大时，又变大。 $\\lambda $较小时，$\\lambda $增大，函数更平滑，能良好适应数据的扰动。 $\\lambda $较大时，函数过于平滑，宛如直线，这显然不能准确预测。 因此，在调节$\\lambda $大小时，也要适当选择。 正则化的一个注意点在regularization中，我们只考虑了w参数，没有考虑bias偏置值参数。 因为正则化是寻找较平滑拟合，而偏置参数只是让函数平移，与平滑无关。 Again：Regularization不考虑bias Fllowing Gradient descent[2] Overfitting and regularization[3] Validation[4] 由于博主也是在学习阶段，学习后，会po上下面内容的链接。 希望能在学习、写博客的过程中，锻炼自己的表达能力，尽量让文风言简意赅又科学严谨。 写博客是为了记录与分享，感谢指正。 Reference[1] “周志华西瓜书p55,待补充” [2] [3] [4]","link":"/2020/02/27/Regression/"}],"tags":[{"name":"机器学习","slug":"机器学习","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"Regression","slug":"Regression","link":"/tags/Regression/"},{"name":"公开课","slug":"公开课","link":"/tags/%E5%85%AC%E5%BC%80%E8%AF%BE/"}],"categories":[{"name":"机器学习-李宏毅","slug":"机器学习-李宏毅","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%9D%8E%E5%AE%8F%E6%AF%85/"}]}