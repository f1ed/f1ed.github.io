{"pages":[],"posts":[{"title":"Paul---big thief(Test)","text":"还是一个测试测试 有一说一Then he showed me what was love. 让我知道什么是爱。 I‘ll be your morning bright goodnight shadow machine. 我会是你早晨的阳光 你的晚安吻 你的影机。 I‘ll be your record player baby if you know what I mean. 如果你希望 我也会是你的唱机。 I‘ll be your real tough cookie with the whiskey breath. 我会是你带着威士忌香味的硬邦邦的曲奇。 I’ll be a killer and a thriller and the cause of our death. 我也可以成为可怕的杀手 让我们一起死去。 In the blossom of the months. 在花开的时候。 I was sure that I’d get driven off with thought. 我将会带着乱七八糟的想法离开。 So I swallowed all of it. 所以我将一切埋在心里。 As I realized there was no one who could kiss away my shit. 因为我意识到没有人可以让我糟透的生活好起来了。 I was your starry-eyed lover and the one that you saw. 我曾是你眼中 看见你时眼睛如星星般闪烁的爱人。 I was your hurricane rider and the woman you’d call. 曾在你需要时像飓风骑士一样飞奔而至。 We were just two moonshiners on the cusp of a breath. 但我们不过是在呼吸交汇中偷偷品尝了烈酒的气息。 And I’ve been burning for you baby since the minute I left. 而从我离开的那一刻起 我都在为你燃烧。 Good night! 晚安！ 有二说二有二说一有二说二有三说三","link":"/2020/02/20/Paul/"},{"title":"「机器学习-李宏毅」：Regression","text":"在YouTube上看台大李宏毅老师的课，看完Regression讲座的感受就是： 好想去抓Pokemon！！！ 这篇文章将总结李宏毅老师Regression的讲座，并尝试实现其demo。 Regression（回归）DefineRegression：是找到一个$function$，进行预测。对输入的feature，输出一个$Scalar$(数值，标量)。 Example Application Look for a $function$ Stock Market Forecast（股票预测） $input$：过去的股价信息 $output$：明天的股价平均值（$Scalar$) Self-Driving Car(自动驾驶) $input$：路况信息 $output$：方向盘角度（$Scalar$) Recommendation（推荐系统） $input$：使用者A、商品B $output$：使用者A购买商品B的可能性 可见，$input$都是一些特征信息，$output$都是一个标量数值，这就是Regression。 Regression Case: Pokenmon 看完这节课，感想：好想去抓宝可梦QAQ 预测一个pokemon进化后的CP（Combat Power，战斗力）值。 为什么要预测呐？ 如果进化后的CP值高，就进化他，不然就把他当糖果，因为宝可梦很难抓的。（？没玩过，我也不懂o r z） 上图妙蛙种子的信息(可能的$input$)： $x_{cp}$：CP值 $x_s$:物种 $x_{hp}$:生命值 $x_w$:重量 $x_h$:高度 output：进化后的CP值。 $x_{cp}$：用下标表示一个object的component。 $x^1$：用上标表示一个完整的object。 Step 1: 找一个Model（function set）Model ：$y = b + w \\cdot x_{cp}$ 假设用上式作为我们的Model，那么这些函数： $ \\begin{aligned} &\\mathrm{f}_{1}: \\mathrm{y}=10.0+9.0 \\cdot \\mathrm{x}_{\\mathrm{cp}}\\\\ &f_{2}: y=9.8+9.2 \\cdot x_{c p}\\\\ &f_{3}: y=-0.8-1.2 \\cdot x_{c p} \\end{aligned} $ 等都属于这个集合，但是显然像$f_3$这种函数是bad，CP值不可能是负数。bad functions 很多，所以在下面的步骤，会说明如何判别一个函数的好坏，自动的选出最好的那个 $function$。 把Model 1一般化，得到线代中的 Linear Model：$y = b+\\sum w_ix_i$ $x_i$：x的feature $b$：bias,偏置值 $w_i$：weight，权重 Step 2: 判别Goodness of Function(Training Data)Training Data假定使用Model ：$y = b + w \\cdot x_{cp}$ Training Data：十只宝可梦，用向量的形式表示。 使用Training data来judge the goodness of function.。 Loss Function(损失函数)概率论：做线性回归，一般使用最小二乘法。一般回归，大多使用极大似然估计。 Loss function $L$ ：$L(f)=L(w,b)=\\sum_{n=1}^{10}(\\hat{y}^n-(b+w\\cdot x_{cp}^n))^2$ 其中的 $\\hat{y}^n-(b+w\\cdot x_{cp}^n)$是Estimation error(估测误差) Loss Function的意义：它的 $input$是一个 $function$，它的 $output$体现了how bad it is,这个函数有多糟/好。 Figure the Result 上图横纵坐标是函数 $L$的参数 $w 、b$，图中的每一个point都是一个 $function $。 color：体现函数的输出，越红越大，说明选择的函数越bad。 所以我们要选择紫色区域结果最小的函数。 而这个得到best function的过程是可以通过无数次迭代实现的。（重复的迭代当时是交给计算机做了） Step 3:迭代找出Best Function$L(w,b)=\\sum_{n=1}^{10}(\\hat{y}^n-(b+w\\cdot x_{cp}^n))^2$ 找到Best Function: $f^{*}=\\arg \\min _{f} L(f)$ 也就是找到参数 $w^{*},b^{*}=\\arg \\min_{w,b} L(w,b)=\\arg \\min_{w,b}\\sum_{n=1}^{10}(\\hat{y}^n-(b+w\\cdot x_{cp}^n))^2$ arg ：argument,变元 arg min：使之最小的变元 arg max：使之最大的变元 据悉，线性回归的参数可以用线性代数的知识，解出closed-form solution（解析解），我先挖个坑QAQ，以后来填这块知识。[1] 在机器学习中，只要$L$函数可微分， 即可用Gradient Descent（梯度下降）的方法来求解。 Gradient Decent（梯度下降）和概率论中的梯度下降估计参数的原理相同，只是计算机不能直接解出方程的解，所以计算机的方法是迭代。 考虑一个参数w*$w^*=\\arg \\min_w L(w)$ 步骤： 随机选取一个初始值 $w^0$ 计算 $ \\frac{{\\rm d}L}{{\\rm d}w}|_{w=w^0}$ &nbsp; &nbsp; $\\begin{equation} w^{1} \\leftarrow w^{0}-\\left.\\eta \\frac{d L}{d w}\\right|_{w=w^{0}} \\end{equation}$ 计算 $ \\frac{{\\rm d}L}{{\\rm d}w}|_{w=w^0}$ &nbsp;&nbsp; $\\begin{equation} w^{2} \\leftarrow w^{1}-\\left.\\eta \\frac{d L}{d w}\\right|_{w=w^{1}} \\end{equation}$ …until $ \\frac{{\\rm d}L}{{\\rm d}w}|_{w=w^n}=0$ 上图迭代过程的几点说明 $\\begin{equation}\\left.\\frac{\\mathrm{d} L}{\\mathrm{d} w}\\right|_{w=w^{i}}\\end{equation}$的正负 如果是negative，也就是该点切线斜率是负的，那应该Increse w，以找到最低点。 Negative $\\rightarrow$ Increase w Positive $\\rightarrow$ Decrease w $-\\left.\\eta \\frac{d L}{d w}\\right|_{w=w^{i}}$：步长 $\\eta$：learning rate（学习速度），事先设好的值。 $-$(负号)：如果 $\\begin{equation}\\left.\\frac{\\mathrm{d} L}{\\mathrm{d} w}\\right|_{w=w^{i}}\\end{equation}$是负的，应该增加w。 Local optimal：局部最优和全局最优 如果是以上图像，则得到的w不是全局最优。 但线性回归的损失函数是凸函数，存在一个全局最优，没有局部最优。 考虑多个参数 $w^{*},b^{*}$ 微积分知识：gradient（梯度，向量)： $\\nabla L=\\left[\\begin{array}{l}\\frac{\\partial L}{\\partial w} \\\\frac{\\partial L}{\\partial b}\\end{array}\\right]$ 考虑多个参数和考虑一个参数思路相同，每次迭代，迭代两个参数。 $w^{*}, b^{*}=\\arg \\min _{w, b} L(w, b)$ 步骤： 随机选取初值 $w^0,b^0$ 计算 $\\left.\\left.\\frac{\\partial L}{\\partial w}\\right|_{w=w^{0}, b=b^{0},} \\frac{\\partial L}{\\partial b}\\right|_{w=w^{0}, b=b^{0}}$ &nbsp; &nbsp; $w^{1} \\leftarrow w^{0}-\\left.\\eta \\frac{\\partial L}{\\partial w}\\right|_{w=w^{0}, b=b^{0}} \\quad b^{1} \\leftarrow b^{0}-\\left.\\eta \\frac{\\partial L}{\\partial b}\\right|_{w=w^{0}, b=b^{0}}$ 计算 $\\left.\\left.\\frac{\\partial L}{\\partial w}\\right|_{w=w^{1}, b=b^{1},} \\frac{\\partial L}{\\partial b}\\right|_{w=w^{1}, b=b^{1}}$ &nbsp; &nbsp; &nbsp; $w^{2} \\leftarrow w^{1}-\\left.\\eta \\frac{\\partial L}{\\partial w}\\right|_{w=w^{1}, b=b^{1}} \\quad b^{2} \\leftarrow b^{1}-\\left.\\eta \\frac{\\partial L}{\\partial b}\\right|_{w=w^{1}, b=b^{1}}$ …until $ \\frac{{\\rm d}L}{{\\rm d}w}|_{w=w^n}=0$, $ \\frac{{\\rm d}L}{{\\rm d}b}|_{b=b^n}=0$ 上图，坐标为 $L(w,b)$函数的参数，Color代表 $L$的大小，越紫值越小。 每一个点都是一个 $function$，沿着梯度方向（图中法线方向）迭代，找到全局最优点。 再次说明：线性回归中，损失函数是convex（凸函数），没有局部最优解。 $\\frac{\\partial L}{\\partial w}$和 $\\frac{\\partial L}{\\partial b}$的公式推导$L(w, b)=\\sum_{n=1}^{10}\\left(\\hat{y}^{n}-\\left(b+w \\cdot x_{c p}^{n}\\right)\\right)^{2}$ 微积分的知识，显然。 数学真香。———我自己 $\\frac{\\partial L}{\\partial w}=\\sum_{n=1}^{10}2\\left(\\hat{y}^{n}-\\left(b+w \\cdot x_{c p}^{n}\\right)\\right)（-x_{cp}^n)$ $\\frac{\\partial L}{\\partial b}=\\sum_{n=1}^{10}2\\left(\\hat{y}^{n}-\\left(b+w \\cdot x_{c p}^{n}\\right)\\right)(-1)$ 实际结果分析Training Data Training Data的Error=31.9，但我们真正关心的是Testing Data的error。 Testing Data 是new Data：另外的Pokemon！。 Testing DataModel 1： $y = b+w\\cdot x_{cp}$ error = 35,比Training Data error更大。 Model 2：$y = b+w_1\\cdot x_{cp}+w_2\\cdot (x_{cp})^2$ Testing error=18.4，比Model 1 好。 Model 3：$y = b+w_1\\cdot x_{cp}+w_2\\cdot (x_{cp})^2+w_3\\cdot(x_{cp})^3$ Testing error=18.1，比Model 2好。 Model 4:$y = b+w_1\\cdot x_{cp}+w_2\\cdot (x_{cp})^2+w_3\\cdot(x_{cp})^3+w_4 \\cdot (x_{cp})^4$ Testing error =28.8,比Model3更差。 Model 5：$y = b+w_1\\cdot x_{cp}+w_2\\cdot (x_{cp})^2+w_3\\cdot(x_{cp})^3+w_4 \\cdot (x_{cp})^4+w_5\\cdot (x_{cp})^5$ Testing error = 232.1,爆炸了一样的差。 &lt;img src=&quot;/images/截屏2020-02-27下午11.11.41.png&quot; alt=&quot;figure 12: Model 5 Error&quot; style=&quot;zoom:33%;&quot; /&gt;Overfiting（过拟合了）从上面5个Model中可以得出，越复杂的函数模型，在Testing data上不一定能得到更好的结果。（过拟合使Training data 的误差越来越小） 所以在选择Model时，需要选择合适的Model。 对模型进行改进如果收集更多的Training Data，可以发现他好像不是一个Linear Model。 Back to step 1:Redesigh the Model从上面那张图，感觉他不是一个Linear Model,而是需要if 是伊布，模型是…，if 是…,可见是和物种有关系。 （很抱歉，我只认识右上角时伊布，QAQ，我也说不出名字） 但用 $\\delta$(微积分学的狄拉克函数)表示条件语句，可以发现，他仍然是一个线性模型。 $\\delta(x_s= \\text{Pidgey)}\\left\\{\\begin{array}{ll}=1 & \\text { If } x_{s}=\\text { Pidgey } \\\\ =0 & \\text { otherwise }\\end{array}\\right.$ $y = b_1\\cdot \\delta_1+w_1\\cdot \\delta_1+b2\\cdot \\delta_2+w_2\\cdot \\delta_2+…$是一个linear model。 拟合出来，Training Data 和Testing Data的error都蛮小的。 如果想让拟合误差更小，还可以考虑其他的feature，重量、高度、HP等。 但同样的，如果函数过于复杂，也会出现Overfitting的情况。 Back to Step 2:Regularization（正则化）对于Linear Model :$y = b+\\sum w_i x_i$ 为什么要正则化？我们希望得到的函数是较平滑的，这样测试时，函数的输出对输入的noise不sensitive，即输入x的细微扰动，并不太会影响输出的结果。 所以当参数越接近0，函数越平滑。因此在原本的loss function后加入 $\\lambda \\sum(w_i)^2$项（ $\\lambda$需手调），可以保证函数较平滑。 正则化： $L = \\sum_n(\\hat{y}^n-(b+\\sum w_i x_i))^2 + \\lambda\\sum(w_i)^2$ $\\lambda $大小的选择 可以得出结论： $\\lambda $越大，Training Error变大了。 当 $\\lambda$更大，损失函数更考虑w参数的取值，更关心函数的平滑程度，而更少的关心拟合的error。 $\\lambda $越大，Testing Error变小了，当 $\\lambda$过大时，又变大。 $\\lambda $较小时，$\\lambda $增大，函数更平滑，能良好适应数据的扰动。 $\\lambda $较大时，函数过于平滑，宛如直线，这显然不能准确预测。 因此，在调节$\\lambda $大小时，也要适当选择。 正则化的一个注意点在regularization中，我们只考虑了w参数，没有考虑bias偏置值参数。 因为正则化是寻找较平滑拟合，而偏置参数只是让函数平移，与平滑无关。 Again：Regularization不考虑bias Fllowing Gradient descent[2] Overfitting and regularization[3] Validation[4] 由于博主也是在学习阶段，学习后，会po上下面内容的链接。 希望能在学习、写博客的过程中，锻炼自己的表达能力，尽量让文风言简意赅又科学严谨。 写博客是为了记录与分享，感谢指正。 Reference[1] “周志华西瓜书p55,待补充” [2] [3] [4]","link":"/2020/02/27/Regression/"},{"title":"Hello f1ed","text":"这只是一个测试 描述恰逢H国国庆，国王邀请n位大臣来玩一个有奖游戏。首先，他让每个大臣在左、右手上面分别写下一个整数，国王自己也在左、右手上各写一个整数。然后，让这n位大臣排成一排，国王站在队伍的最前面。排好队后，所有的大臣都会获得国王奖赏的若干金币，每位大臣获得的金币数分别是：排在该大臣前面的所有人的左手上的数的乘积除以他自己右手上的数，然后向下取整得到的结果。国王不希望某一个大臣获得特别多的奖赏，所以他想请你帮他重新安排一下队伍的顺序，使得获得奖赏最多的大臣，所获奖赏尽可能的少。注意，国王的位置始终在队伍的最前面。 输入格式第一行包含一个整数n，表示大臣的人数。第二行包含两个整数a和b，之间用一个空格隔开，分别表示国王左手和右手上的整数。接下来n行，每行包含两个整数a和b，之间用一个空格隔开，分别表示每个大臣左手和右手上的整数。 $x_2+\\Sigma_1^3$ Solution… code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;ctime&gt;#include&lt;cstdlib&gt;#include&lt;cmath&gt;#include&lt;cstring&gt;#include&lt;string&gt;#include&lt;set&gt;#include&lt;map&gt;#include&lt;vector&gt;#include&lt;queue&gt;#include&lt;algorithm&gt;#ifdef WIN32#define AUTO \"%I64d\"#else#define AUTO \"%lld\"#endif#define INF 0x3f3f3f3f#define CLOCK CLOCKS_PER_SEC#define cle(x) memset(x,0,sizeof(x))#define maxcle(x) memset(x,0x3f,sizeof(x))#define mincle(x) memset(x,-1,sizeof(x))#define maxx(x1,x2,x3) max(x1,max(x2,x3))#define minn(x1,x2,x3) min(x1,min(x2,x3))#define cop(a,x) memcpy(x,a,sizeof(a))#define FROP \"hdu\"#define LL long long#define smin(x,tmp) x=min(x,tmp)#define smax(x,tmp) x=max(x,tmp)using namespace std;const int N = 1005;struct bigint{ static const int P =1,M=10; int w[4050]; bigint(){cle(w);w[0]=1;} void read() { string s; cin&gt;&gt;s; int now=1,c1=1,ct=0; for(int i = s.size()-1;i&gt;=0;i--) { w[now]+=(s[i]-'0')*c1; c1*=10; ct++; if(ct==P&amp;&amp;i){c1=1;ct=0;now++;} } w[0]=now; } bigint operator * (const int &amp;b) { bigint a=*this; bigint c; int &amp;len=c.w[0]; len=a.w[0]+5; for(int i = 1; i &lt;= len;i++) { c.w[i]+=a.w[i]*b; c.w[i+1]=c.w[i]/M; c.w[i]%=M; } while(len&gt;1&amp;&amp;!c.w[len])len--; return c; } bigint operator /(const int &amp;b) { bigint a=*this; bigint c; int &amp;len=c.w[0]; len=a.w[0]; int tmp=0; for(int i = len; i ;i--) { tmp+=a.w[i]; if(tmp&gt;=b) { c.w[i]+=tmp/b; tmp%=b; } tmp*=M; } while(len&gt;1&amp;&amp;!c.w[len])len--; return c; } bool operator &lt; (const bigint &amp;b)const { bigint a=*this; if(a.w[0]^b.w[0])return a.w[0]&lt;b.w[0]; for(int i = a.w[0];i;i--) if(a.w[i]^b.w[i])return a.w[i]&lt;b.w[i]; return false; } void print() { printf(\"%d\",w[w[0]]); for(int i = w[0]-1;i;i--) printf(\"%0*d\",P,w[i]); }}L,R;int n;struct ii{ int l,r; ii(int l =0,int r=0):l(l),r(r){ } bool operator &lt; (const ii &amp;b)const { return l*r&lt;b.l*b.r; }}node[N];int main(){ freopen(FROP\".in\",\"r\",stdin); freopen(FROP\".out\",\"w\",stdout); scanf(\"%d\",&amp;n); L.read(); R.read(); for(int i = 1;i &lt;= n; i++) { int x,y; scanf(\"%d%d\",&amp;x,&amp;y); node[i]=ii(x,y); } sort(node+1,node+n+1); bigint ans,tmp=L; for(int i = 1; i &lt;= n; i++) { bigint x=tmp/node[i].r; if(ans&lt;x)ans=x; tmp=tmp*node[i].l; } ans.print(); return 0;} reference[1] ……xxx [2]","link":"/2020/02/24/hello-f1ed/"}],"tags":[{"name":"测试","slug":"测试","link":"/tags/%E6%B5%8B%E8%AF%95/"},{"name":"机器学习","slug":"机器学习","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"Regression","slug":"Regression","link":"/tags/Regression/"},{"name":"公开课","slug":"公开课","link":"/tags/%E5%85%AC%E5%BC%80%E8%AF%BE/"}],"categories":[{"name":"测试","slug":"测试","link":"/categories/%E6%B5%8B%E8%AF%95/"},{"name":"机器学习-李宏毅","slug":"机器学习-李宏毅","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%9D%8E%E5%AE%8F%E6%AF%85/"}]}